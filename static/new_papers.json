[{"title": "Attention is all you need", "link": "https://proceedings.neurips.cc/paper/7181-attention-is-all", "abstract": "\u2026 we propose the Transformer, a model architecture eschewing recurrence and instead relying entirely on an attention \u2026 The Transformer allows for significantly more parallelization and \u2026"}, {"title": "Attention is all you need in speech separation", "link": "https://ieeexplore.ieee.org/abstract/document/9413901/", "abstract": "\u2026 In this paper, we propose a novel model called SepFormer (Separation Transformer), which is \u2026 We analyze the speed of our best model for both WSJ0-2Mix and WSJ0-3Mix datasets. \u2026"}, {"title": "Fastformer: Additive attention can be all you need", "link": "https://arxiv.org/abs/2108.09084", "abstract": "Abstract:Transformer is a powerful model for text understanding. However, it is inefficient due to its quadratic complexity to input sequence length. Although there are many methods on Transformer acceleration, they are still either inefficient on long sequences or not effective enough. In this paper, we propose Fastformer, which is an efficient Transformer model based on additive attention. In Fastformer, instead of modeling the pair-wise interactions between tokens, we first use additive attention mechanism to model global contexts, and then further transform each token representation based on its interaction with global context representations. In this way, Fastformer can achieve effective context modeling with linear complexity. Extensive experiments on five datasets show that Fastformer is much more efficient than many existing Transformer models and can meanwhile achieve comparable or even better long text modeling performance."}, {"title": "Attention is all you need. NIPS (2017)", "link": "https://www.codetds.com/article/15517262", "abstract": "\u5360\u4e3b\u5bfc\u5730\u4f4d\u7684\u5e8f\u5217\u8f6c\u5bfc\u6a21\u578b\u57fa\u4e8e\u590d\u6742\u7684\u9012\u5f52\u6216\u5377\u79ef\u795e\u7ecf\u7f51\u7edc, \u5305\u62ec\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668. \u6027\u80fd\u6700\u597d\u7684 \u6a21\u578b\u8fd8\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\u8fde\u63a5\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668. \u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7b80\u5355\u7f51\u7edc\u67b6\u6784, \u5373Transformer, \u2026"}, {"title": "A multiscale visualization of attention in the transformer model", "link": "https://arxiv.org/abs/1906.05714", "abstract": "Abstract:The Transformer is a sequence model that forgoes traditional recurrent architectures in favor of a fully attention-based approach. Besides improving performance, an advantage of using attention is that it can also help to interpret a model by showing how the model assigns weight to different input elements. However, the multi-layer, multi-head attention mechanism in the Transformer model can be difficult to decipher. To make the model more accessible, we introduce an open-source tool that visualizes attention at multiple scales, each of which provides a unique perspective on the attention mechanism. We demonstrate the tool on BERT and OpenAI GPT-2 and present three example use cases: detecting model bias, locating relevant attention heads, and linking neurons to model behavior."}, {"title": "Synthesizer: Rethinking self-attention for transformer models", "link": "https://proceedings.mlr.press/v139/tay21a.html", "abstract": "\u2026 self-attention mechanism in Transformer models. We delve deeper, starting with replacing the pairwise dot products with what we call synthesizing functions that learn attention matrices \u2026"}, {"title": "Attention is all you need", "link": "http://www.aiotlab.org/teaching/intro2ai/slides/10_attention_n_bert.pdf", "abstract": "\u2026 \u2022 ELMo\u2019s language model was bi-directional, but the openAI transformer only trains a forward language model. \u2022 Could we build a transformer-based model whose language model \u2026"}, {"title": "Analyzing the structure of attention in a transformer language model", "link": "https://arxiv.org/abs/1906.04284", "abstract": "Abstract:The Transformer is a fully attention-based alternative to recurrent networks that has achieved state-of-the-art results across a range of NLP tasks. In this paper, we analyze the structure of attention in a Transformer language model, the GPT-2 small pretrained model. We visualize attention for individual instances and analyze the interaction between attention and syntax over a large corpus. We find that attention targets different parts of speech at different layer depths within the model, and that attention aligns with dependency relations most strongly in the middle layers. We also find that the deepest layers of the model capture the most distant relationships. Finally, we extract exemplar sentences that reveal highly specific patterns targeted by particular attention heads."}, {"title": "Attention is not all you need: Pure attention loses rank doubly exponentially with depth", "link": "https://proceedings.mlr.press/v139/dong21a.html", "abstract": "\u2026 are attainable with increased model capacity and training time, our focus is to study the effects of path \u2026 as path length increases stayed consistent across model sizes in all experiments. \u2026"}, {"title": "Is space-time attention all you need for video understanding?", "link": "https://proceedings.mlr.press/v139/bertasius21a/bertasius21a-supp.pdf", "abstract": "\u2026 We report that this variant of our model produced results about 3% worse than \u2026 attention from the output token to the input space on Something-Something-V2. Our model learns to focus \u2026"}]